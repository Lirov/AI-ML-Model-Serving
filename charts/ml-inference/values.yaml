image:
  repository: ml-inference
  tag: "0.1.0"
  pullPolicy: IfNotPresent

replicaCount: 1

service:
  type: ClusterIP
  port: 80
  targetPort: 8000

resources:
  requests:
    cpu: "100m"
    memory: "128Mi"
  limits:
    cpu: "500m"
    memory: "512Mi"

ingress:
  enabled: true
  className: nginx
  host: ml.192.168.49.2.nip.io         # change for your domain
  path: /
  annotations: {}               # default; canary added later

hpa:
  enabled: true
  minReplicas: 1
  maxReplicas: 5
  targetCPUUtilizationPercentage: 60

env:
  MODEL_PATH: "/app/app/model/model.joblib"
